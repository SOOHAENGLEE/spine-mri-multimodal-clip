import sys
import os
import argparse
import yaml
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from transformers import AutoTokenizer
from tqdm import tqdm
from accelerate import Accelerator, DistributedDataParallelKwargs

# ë°ë“œë½ ë°©ì§€
os.environ["TOKENIZERS_PARALLELISM"] = "false"

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(current_dir))

from src.data.datasets import CLIPDataset
from src.models.clip import SpineCLIP
from src.utils.logger import ExperimentLogger
from src.utils.metrics import calculate_retrieval_metrics

def main(args):
    with open(args.config, 'r') as f:
        cfg = yaml.safe_load(f)
        
    TASK_MODE = args.mode
    SAVE_DIR = f"{cfg['paths']['result_dir']}/clip_{TASK_MODE}"
    
    # [DDP ì„¤ì •] find_unused_parameters=TrueëŠ” ì´ì œ í•„ìš” ì—†ê±°ë‚˜ Falseê°€ ë” ì•ˆì „í•  ìˆ˜ ìžˆìŒ
    # í•˜ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ì¼œë‘ë˜, ëª¨ë¸ Forward ìˆ˜ì •ìœ¼ë¡œ í•´ê²°
    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)
    accelerator = Accelerator(log_with="all", project_dir=SAVE_DIR, kwargs_handlers=[ddp_kwargs])
    device = accelerator.device

    if accelerator.is_main_process:
        logger = ExperimentLogger(SAVE_DIR)
        print(f"ðŸš€ Training CLIP ({TASK_MODE}) on {accelerator.num_processes} GPUs")

    tokenizer = AutoTokenizer.from_pretrained(cfg['models']['clip']['text_encoder'])
    data_path = f"{cfg['paths']['output_dir']}/augmented.json"
    if not os.path.exists(data_path): data_path = f"{cfg['paths']['output_dir']}/labeled.json"

    ds = CLIPDataset(data_path, tokenizer, img_size=tuple(cfg['train']['img_size']), text_col=TASK_MODE, is_train=True)
    train_size = int(0.9 * len(ds))
    train_ds, val_ds = random_split(ds, [train_size, len(ds) - train_size])
    
    train_loader = DataLoader(train_ds, batch_size=cfg['train']['batch_size'], shuffle=True, 
                              num_workers=4, pin_memory=True, persistent_workers=True, drop_last=True)
    val_loader = DataLoader(val_ds, batch_size=cfg['train']['batch_size'], shuffle=False, 
                            num_workers=4, pin_memory=True, persistent_workers=True, drop_last=False)
    
    model = SpineCLIP(cfg).to(device)
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=float(cfg['train']['lr']), weight_decay=cfg['train']['weight_decay'])
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg['train']['epochs'])

    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(model, optimizer, train_loader, val_loader, scheduler)

    best_mrr = 0.0

    for epoch in range(cfg['train']['epochs']):
        model.train()
        train_loss = 0
        
        iterator = tqdm(train_loader, desc=f"Ep {epoch+1}", disable=not accelerator.is_main_process)
        
        for batch in iterator:
            imgs = batch['images']
            ids = batch['input_ids']
            mask = batch['attention_mask']
            
            # Forward (ì´ì œ scaleë„ ë¦¬í„´ë°›ìŒ)
            img_emb, txt_emb, scale = model(imgs, ids, mask)
            
            # [Safe Global Loss Implementation]
            # 1. Gather all embeddings (Gradient ë¯¸í¬í•¨)
            # accelerator.gather()ëŠ” detachëœ í…ì„œë¥¼ ëª¨ì•„ì¤ë‹ˆë‹¤.
            all_img = accelerator.gather(img_emb)
            all_txt = accelerator.gather(txt_emb)
            
            # 2. ë‚´ ë°ì´í„°(Local)ê°€ ì „ì²´(Global)ì—ì„œ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€ ì°¾ê¸°
            # (Gatherëœ í…ì„œëŠ” [GPU0, GPU1, GPU2, GPU3] ìˆœì„œë¡œ ë¶™ì–´ìžˆìŒ)
            
            # 3. í•˜ì§€ë§Œ ë¯¸ë¶„ì´ ëŠê¸°ë©´ í•™ìŠµì´ ì•ˆ ë˜ë¯€ë¡œ, 
            # "Local Image vs Global Text" + "Local Text vs Global Image" ë¡œ ê³„ì‚°í•´ì•¼ í•¨.
            # ì´ëŸ¬ë©´ Local ë¶€ë¶„ì—ëŠ” Gradientê°€ íë¥´ê³ , Global ë¶€ë¶„(ë‚¨ì˜ ê²ƒ)ì€ Negative Sample ì—­í• ë§Œ í•¨.
            
            # Matmul: (Local_B, D) @ (Global_B, D).T -> (Local_B, Global_B)
            logits_per_image = scale * img_emb @ all_txt.t()
            logits_per_text = scale * txt_emb @ all_img.t()
            
            # ì •ë‹µ ë¼ë²¨ (Global ë‚´ì—ì„œì˜ ë‚´ ìœ„ì¹˜)
            # rank 0: 0~15, rank 1: 16~31 ...
            local_batch_size = img_emb.size(0)
            global_offset = accelerator.process_index * local_batch_size
            labels = torch.arange(local_batch_size, device=device) + global_offset
            
            loss = (F.cross_entropy(logits_per_image, labels) + F.cross_entropy(logits_per_text, labels)) / 2
            
            accelerator.backward(loss)
            optimizer.step()
            optimizer.zero_grad()
            
            train_loss += loss.item()
            
        scheduler.step()
        
        # Validation
        model.eval()
        metrics_sum = {'hit1':0, 'mrr':0}
        
        for batch in val_loader:
            with torch.no_grad():
                # Valì—ì„œëŠ” scale ê·¸ëƒ¥ ì ‘ê·¼í•´ë„ ë¨ (Backward ì•ˆí•˜ë‹ˆê¹Œ)
                # í•˜ì§€ë§Œ model forward í˜•ì‹ì´ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ë§žì¶°ì¤Œ
                img_emb, txt_emb, scale = model(batch['images'], batch['input_ids'], batch['attention_mask'])
                
                logits = scale * img_emb @ txt_emb.t()
                labels = torch.arange(len(img_emb), device=device)
                
                metrics = calculate_retrieval_metrics(logits, labels)
                metrics_sum['hit1'] += metrics['hit1']
                metrics_sum['mrr'] += metrics['mrr']

        if accelerator.is_main_process:
            avg_loss = train_loss / len(train_loader)
            avg_hit1 = metrics_sum['hit1'] / len(val_loader)
            print(f"Ep {epoch+1} | Loss: {avg_loss:.4f} | Val Hit@1: {avg_hit1:.3f}")
            logger.log(epoch+1, {'train_loss': avg_loss, 'val_acc': avg_hit1})
            
            if avg_hit1 > best_mrr:
                best_mrr = avg_hit1
                torch.save(accelerator.unwrap_model(model).state_dict(), f"{SAVE_DIR}/best_model.pt")

    if accelerator.is_main_process: logger.plot()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="configs/model_config.yaml")
    parser.add_argument("--mode", type=str, default="summary")
    args = parser.parse_args()
    main(args)